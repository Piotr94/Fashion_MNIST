{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion-MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Piotr94/Fashion_MNIST/blob/master/Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRE1Wp-mA2vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IdcmTO2lJPx",
        "colab_type": "code",
        "outputId": "34796bac-5552-42a0-a9ad-b32004fb6870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f8ad42bc4b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wmud5IDBQ7N",
        "colab_type": "code",
        "outputId": "554f9663-9ed5-4cc2-badd-056ca6f6d396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "train_transform = torchvision.transforms.Compose(\n",
        "    # data augmentation: rotation, flipping and adding noise\n",
        "    [torchvision.transforms.RandomRotation(25),\n",
        "     torchvision.transforms.RandomHorizontalFlip(),\n",
        "     torchvision.transforms.ToTensor(),\n",
        "     torchvision.transforms.Lambda(lambda x: x + 0.01*torch.rand(x.shape)),\n",
        "     torchvision.transforms.Normalize((0.5,), (0.5,))]\n",
        ")\n",
        "test_transform = torchvision.transforms.Compose(\n",
        "     [torchvision.transforms.ToTensor(),\n",
        "     torchvision.transforms.Normalize((0.5,), (0.5,))]\n",
        ")\n",
        "trainset = torchvision.datasets.FashionMNIST(root=\"./\", train=True, download=True, transform=train_transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.FashionMNIST(root=\"./\", train=False, download=True, transform=test_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = (\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\",\n",
        "           \"Sneaker\", \"Bag\", \"Ankle boot\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:02, 10760590.12it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 94134.27it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:01, 3890386.87it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 32270.85it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFxwbosHJfcl",
        "colab_type": "code",
        "outputId": "905c6b18-5f8e-43b5-cdaa-d4abf0928429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # Exchange convolution layers with kernels 5x5 for two stacked convolution layers with kernels 3x3\n",
        "    # there is less parameters so learning is faster and overfitting is smaller\n",
        "    self.conv_layer1 = nn.Sequential(\n",
        "        nn.Conv2d(1, 32, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(32), # batch normalization after every layer except the last one\n",
        "    )\n",
        "    self.conv_layer3 = nn.Sequential(\n",
        "        nn.Conv2d(32, 32, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    # additional convolution layer with padding to extract features of higher level\n",
        "    self.conv_layer2 = nn.Sequential(\n",
        "        nn.Conv2d(32, 32, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(32),\n",
        "    )\n",
        "    self.conv_layer4 = nn.Sequential(\n",
        "        nn.Conv2d(32, 64, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64),\n",
        "    )\n",
        "    self.conv_layer5 = nn.Sequential(\n",
        "        nn.Conv2d(64, 64, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.Dropout(0.3), # Droput to delay moment of overfitting\n",
        "        nn.Linear(64*4*4, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(100),\n",
        "    )\n",
        "    self.fc2 = nn.Linear(100, 10, )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_layer1(x)\n",
        "    x = self.conv_layer2(x)\n",
        "    x = self.conv_layer3(x)\n",
        "    x = self.conv_layer4(x)\n",
        "    x = self.conv_layer5(x)\n",
        "    x = x.view(-1, 64*4*4)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv_layer1): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv_layer3): Sequential(\n",
              "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_layer2): Sequential(\n",
              "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv_layer4): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv_layer5): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc1): Sequential(\n",
              "    (0): Dropout(p=0.3, inplace=False)\n",
              "    (1): Linear(in_features=1024, out_features=100, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DBI024vRXfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# weight decay is set to small value, bigger values were slowing down learning and causing converging at smaller level\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.005, momentum=0.7, weight_decay=0.00005, nesterov=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfBDqNwRWAft",
        "colab_type": "code",
        "outputId": "6fcda1cc-f723-4136-daf6-d812466186ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "min_val_loss = float('inf')\n",
        "epochs_wo_improve = 0\n",
        "model_path = \"./fashion_mnist_model\"\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "for epoch in range(250):\n",
        "  print(\"\\nEpoch %d\" % (epoch,)) \n",
        "  total = 0\n",
        "  correct = 0\n",
        "  running_loss = 0.0\n",
        "  net = net.train()\n",
        "  for i, data in enumerate(trainloader, 1):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    total += labels.size(0)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  print('training loss: %.3f' %\n",
        "        (running_loss / i,))\n",
        "  train_losses.append(running_loss / i)\n",
        "  print('training accuracy: %.2f %%' % \n",
        "        (100*correct/total,))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    net = net.eval()\n",
        "    val_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, data in enumerate(testloader, 1):\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      val_loss += criterion(outputs, labels).item()\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  print('validation loss: %.3f' % \n",
        "        (val_loss/i,))\n",
        "  validation_losses.append(val_loss / i)\n",
        "  print('validation accuracy: %.2f %%' % \n",
        "        (100*correct/total,))\n",
        "  # early stopping with patience = 40 epochs\n",
        "  if val_loss < min_val_loss:\n",
        "    print(\"model saved\")\n",
        "    torch.save(net, model_path)\n",
        "    min_val_loss = val_loss\n",
        "    epochs_wo_improve = 0\n",
        "  else:\n",
        "    epochs_wo_improve += 1\n",
        "    if epochs_wo_improve == 40:\n",
        "      net = torch.load(model_path)\n",
        "      break\n",
        "\n",
        "print(\"Training is finished\")\n",
        "plt.plot(train_losses)\n",
        "plt.plot(validation_losses)\n",
        "plt.legend([\"train loss\", \"validation loss\"])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 0\n",
            "training loss: 0.572\n",
            "training accuracy: 79.55 %\n",
            "validation loss: 0.389\n",
            "validation accuracy: 85.97 %\n",
            "model saved\n",
            "\n",
            "Epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm1d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training loss: 0.413\n",
            "training accuracy: 85.19 %\n",
            "validation loss: 0.353\n",
            "validation accuracy: 87.34 %\n",
            "model saved\n",
            "\n",
            "Epoch 2\n",
            "training loss: 0.363\n",
            "training accuracy: 86.82 %\n",
            "validation loss: 0.309\n",
            "validation accuracy: 88.78 %\n",
            "model saved\n",
            "\n",
            "Epoch 3\n",
            "training loss: 0.343\n",
            "training accuracy: 87.64 %\n",
            "validation loss: 0.307\n",
            "validation accuracy: 89.00 %\n",
            "model saved\n",
            "\n",
            "Epoch 4\n",
            "training loss: 0.332\n",
            "training accuracy: 88.04 %\n",
            "validation loss: 0.311\n",
            "validation accuracy: 88.67 %\n",
            "\n",
            "Epoch 5\n",
            "training loss: 0.314\n",
            "training accuracy: 88.63 %\n",
            "validation loss: 0.274\n",
            "validation accuracy: 90.51 %\n",
            "model saved\n",
            "\n",
            "Epoch 6\n",
            "training loss: 0.300\n",
            "training accuracy: 89.10 %\n",
            "validation loss: 0.274\n",
            "validation accuracy: 90.30 %\n",
            "\n",
            "Epoch 7\n",
            "training loss: 0.291\n",
            "training accuracy: 89.42 %\n",
            "validation loss: 0.272\n",
            "validation accuracy: 90.12 %\n",
            "model saved\n",
            "\n",
            "Epoch 8\n",
            "training loss: 0.284\n",
            "training accuracy: 89.74 %\n",
            "validation loss: 0.269\n",
            "validation accuracy: 90.31 %\n",
            "model saved\n",
            "\n",
            "Epoch 9\n",
            "training loss: 0.275\n",
            "training accuracy: 90.00 %\n",
            "validation loss: 0.257\n",
            "validation accuracy: 90.88 %\n",
            "model saved\n",
            "\n",
            "Epoch 10\n",
            "training loss: 0.270\n",
            "training accuracy: 90.28 %\n",
            "validation loss: 0.251\n",
            "validation accuracy: 91.03 %\n",
            "model saved\n",
            "\n",
            "Epoch 11\n",
            "training loss: 0.266\n",
            "training accuracy: 90.39 %\n",
            "validation loss: 0.252\n",
            "validation accuracy: 90.89 %\n",
            "\n",
            "Epoch 12\n",
            "training loss: 0.259\n",
            "training accuracy: 90.58 %\n",
            "validation loss: 0.242\n",
            "validation accuracy: 91.28 %\n",
            "model saved\n",
            "\n",
            "Epoch 13\n",
            "training loss: 0.256\n",
            "training accuracy: 90.75 %\n",
            "validation loss: 0.235\n",
            "validation accuracy: 91.63 %\n",
            "model saved\n",
            "\n",
            "Epoch 14\n",
            "training loss: 0.250\n",
            "training accuracy: 90.88 %\n",
            "validation loss: 0.237\n",
            "validation accuracy: 91.52 %\n",
            "\n",
            "Epoch 15\n",
            "training loss: 0.252\n",
            "training accuracy: 90.89 %\n",
            "validation loss: 0.237\n",
            "validation accuracy: 91.69 %\n",
            "\n",
            "Epoch 16\n",
            "training loss: 0.243\n",
            "training accuracy: 91.15 %\n",
            "validation loss: 0.234\n",
            "validation accuracy: 91.76 %\n",
            "model saved\n",
            "\n",
            "Epoch 17\n",
            "training loss: 0.240\n",
            "training accuracy: 91.38 %\n",
            "validation loss: 0.231\n",
            "validation accuracy: 91.77 %\n",
            "model saved\n",
            "\n",
            "Epoch 18\n",
            "training loss: 0.240\n",
            "training accuracy: 91.30 %\n",
            "validation loss: 0.239\n",
            "validation accuracy: 91.41 %\n",
            "\n",
            "Epoch 19\n",
            "training loss: 0.236\n",
            "training accuracy: 91.37 %\n",
            "validation loss: 0.238\n",
            "validation accuracy: 91.80 %\n",
            "\n",
            "Epoch 20\n",
            "training loss: 0.234\n",
            "training accuracy: 91.56 %\n",
            "validation loss: 0.231\n",
            "validation accuracy: 91.71 %\n",
            "model saved\n",
            "\n",
            "Epoch 21\n",
            "training loss: 0.229\n",
            "training accuracy: 91.67 %\n",
            "validation loss: 0.225\n",
            "validation accuracy: 91.81 %\n",
            "model saved\n",
            "\n",
            "Epoch 22\n",
            "training loss: 0.227\n",
            "training accuracy: 91.67 %\n",
            "validation loss: 0.226\n",
            "validation accuracy: 92.23 %\n",
            "\n",
            "Epoch 23\n",
            "training loss: 0.228\n",
            "training accuracy: 91.70 %\n",
            "validation loss: 0.225\n",
            "validation accuracy: 92.02 %\n",
            "\n",
            "Epoch 24\n",
            "training loss: 0.223\n",
            "training accuracy: 91.94 %\n",
            "validation loss: 0.223\n",
            "validation accuracy: 92.07 %\n",
            "model saved\n",
            "\n",
            "Epoch 25\n",
            "training loss: 0.221\n",
            "training accuracy: 91.99 %\n",
            "validation loss: 0.225\n",
            "validation accuracy: 91.85 %\n",
            "\n",
            "Epoch 26\n",
            "training loss: 0.219\n",
            "training accuracy: 92.08 %\n",
            "validation loss: 0.224\n",
            "validation accuracy: 92.03 %\n",
            "\n",
            "Epoch 27\n",
            "training loss: 0.217\n",
            "training accuracy: 92.05 %\n",
            "validation loss: 0.226\n",
            "validation accuracy: 92.21 %\n",
            "\n",
            "Epoch 28\n",
            "training loss: 0.216\n",
            "training accuracy: 92.02 %\n",
            "validation loss: 0.220\n",
            "validation accuracy: 92.49 %\n",
            "model saved\n",
            "\n",
            "Epoch 29\n",
            "training loss: 0.217\n",
            "training accuracy: 92.10 %\n",
            "validation loss: 0.217\n",
            "validation accuracy: 92.62 %\n",
            "model saved\n",
            "\n",
            "Epoch 30\n",
            "training loss: 0.214\n",
            "training accuracy: 92.11 %\n",
            "validation loss: 0.216\n",
            "validation accuracy: 92.38 %\n",
            "model saved\n",
            "\n",
            "Epoch 31\n",
            "training loss: 0.210\n",
            "training accuracy: 92.33 %\n",
            "validation loss: 0.219\n",
            "validation accuracy: 92.21 %\n",
            "\n",
            "Epoch 32\n",
            "training loss: 0.211\n",
            "training accuracy: 92.32 %\n",
            "validation loss: 0.214\n",
            "validation accuracy: 92.53 %\n",
            "model saved\n",
            "\n",
            "Epoch 33\n",
            "training loss: 0.205\n",
            "training accuracy: 92.53 %\n",
            "validation loss: 0.214\n",
            "validation accuracy: 92.52 %\n",
            "\n",
            "Epoch 34\n",
            "training loss: 0.208\n",
            "training accuracy: 92.30 %\n",
            "validation loss: 0.212\n",
            "validation accuracy: 92.62 %\n",
            "model saved\n",
            "\n",
            "Epoch 35\n",
            "training loss: 0.204\n",
            "training accuracy: 92.47 %\n",
            "validation loss: 0.213\n",
            "validation accuracy: 92.41 %\n",
            "\n",
            "Epoch 36\n",
            "training loss: 0.202\n",
            "training accuracy: 92.69 %\n",
            "validation loss: 0.217\n",
            "validation accuracy: 92.17 %\n",
            "\n",
            "Epoch 37\n",
            "training loss: 0.204\n",
            "training accuracy: 92.58 %\n",
            "validation loss: 0.205\n",
            "validation accuracy: 92.56 %\n",
            "model saved\n",
            "\n",
            "Epoch 38\n",
            "training loss: 0.199\n",
            "training accuracy: 92.77 %\n",
            "validation loss: 0.207\n",
            "validation accuracy: 92.71 %\n",
            "\n",
            "Epoch 39\n",
            "training loss: 0.200\n",
            "training accuracy: 92.73 %\n",
            "validation loss: 0.210\n",
            "validation accuracy: 92.68 %\n",
            "\n",
            "Epoch 40\n",
            "training loss: 0.197\n",
            "training accuracy: 92.76 %\n",
            "validation loss: 0.206\n",
            "validation accuracy: 92.70 %\n",
            "\n",
            "Epoch 41\n",
            "training loss: 0.195\n",
            "training accuracy: 92.97 %\n",
            "validation loss: 0.207\n",
            "validation accuracy: 92.85 %\n",
            "\n",
            "Epoch 42\n",
            "training loss: 0.197\n",
            "training accuracy: 92.74 %\n",
            "validation loss: 0.204\n",
            "validation accuracy: 93.02 %\n",
            "model saved\n",
            "\n",
            "Epoch 43\n",
            "training loss: 0.195\n",
            "training accuracy: 92.86 %\n",
            "validation loss: 0.209\n",
            "validation accuracy: 92.68 %\n",
            "\n",
            "Epoch 44\n",
            "training loss: 0.193\n",
            "training accuracy: 92.91 %\n",
            "validation loss: 0.206\n",
            "validation accuracy: 92.61 %\n",
            "\n",
            "Epoch 45\n",
            "training loss: 0.191\n",
            "training accuracy: 92.99 %\n",
            "validation loss: 0.200\n",
            "validation accuracy: 92.99 %\n",
            "model saved\n",
            "\n",
            "Epoch 46\n",
            "training loss: 0.194\n",
            "training accuracy: 92.94 %\n",
            "validation loss: 0.203\n",
            "validation accuracy: 92.92 %\n",
            "\n",
            "Epoch 47\n",
            "training loss: 0.191\n",
            "training accuracy: 93.08 %\n",
            "validation loss: 0.206\n",
            "validation accuracy: 92.76 %\n",
            "\n",
            "Epoch 48\n",
            "training loss: 0.188\n",
            "training accuracy: 93.22 %\n",
            "validation loss: 0.203\n",
            "validation accuracy: 92.70 %\n",
            "\n",
            "Epoch 49\n",
            "training loss: 0.188\n",
            "training accuracy: 93.07 %\n",
            "validation loss: 0.201\n",
            "validation accuracy: 92.97 %\n",
            "\n",
            "Epoch 50\n",
            "training loss: 0.190\n",
            "training accuracy: 93.06 %\n",
            "validation loss: 0.207\n",
            "validation accuracy: 93.03 %\n",
            "\n",
            "Epoch 51\n",
            "training loss: 0.186\n",
            "training accuracy: 93.18 %\n",
            "validation loss: 0.208\n",
            "validation accuracy: 92.78 %\n",
            "\n",
            "Epoch 52\n",
            "training loss: 0.186\n",
            "training accuracy: 93.10 %\n",
            "validation loss: 0.201\n",
            "validation accuracy: 93.01 %\n",
            "\n",
            "Epoch 53\n",
            "training loss: 0.185\n",
            "training accuracy: 93.24 %\n",
            "validation loss: 0.213\n",
            "validation accuracy: 92.85 %\n",
            "\n",
            "Epoch 54\n",
            "training loss: 0.184\n",
            "training accuracy: 93.30 %\n",
            "validation loss: 0.216\n",
            "validation accuracy: 92.61 %\n",
            "\n",
            "Epoch 55\n",
            "training loss: 0.183\n",
            "training accuracy: 93.20 %\n",
            "validation loss: 0.200\n",
            "validation accuracy: 93.24 %\n",
            "\n",
            "Epoch 56\n",
            "training loss: 0.180\n",
            "training accuracy: 93.45 %\n",
            "validation loss: 0.200\n",
            "validation accuracy: 93.03 %\n",
            "model saved\n",
            "\n",
            "Epoch 57\n",
            "training loss: 0.180\n",
            "training accuracy: 93.37 %\n",
            "validation loss: 0.199\n",
            "validation accuracy: 92.99 %\n",
            "model saved\n",
            "\n",
            "Epoch 58\n",
            "training loss: 0.178\n",
            "training accuracy: 93.45 %\n",
            "validation loss: 0.202\n",
            "validation accuracy: 92.87 %\n",
            "\n",
            "Epoch 59\n",
            "training loss: 0.180\n",
            "training accuracy: 93.40 %\n",
            "validation loss: 0.201\n",
            "validation accuracy: 93.18 %\n",
            "\n",
            "Epoch 60\n",
            "training loss: 0.179\n",
            "training accuracy: 93.53 %\n",
            "validation loss: 0.215\n",
            "validation accuracy: 92.57 %\n",
            "\n",
            "Epoch 61\n",
            "training loss: 0.179\n",
            "training accuracy: 93.51 %\n",
            "validation loss: 0.202\n",
            "validation accuracy: 92.78 %\n",
            "\n",
            "Epoch 62\n",
            "training loss: 0.175\n",
            "training accuracy: 93.50 %\n",
            "validation loss: 0.204\n",
            "validation accuracy: 92.64 %\n",
            "\n",
            "Epoch 63\n",
            "training loss: 0.178\n",
            "training accuracy: 93.50 %\n",
            "validation loss: 0.198\n",
            "validation accuracy: 93.10 %\n",
            "model saved\n",
            "\n",
            "Epoch 64\n",
            "training loss: 0.176\n",
            "training accuracy: 93.57 %\n",
            "validation loss: 0.196\n",
            "validation accuracy: 93.03 %\n",
            "model saved\n",
            "\n",
            "Epoch 65\n",
            "training loss: 0.174\n",
            "training accuracy: 93.61 %\n",
            "validation loss: 0.197\n",
            "validation accuracy: 92.95 %\n",
            "\n",
            "Epoch 66\n",
            "training loss: 0.175\n",
            "training accuracy: 93.66 %\n",
            "validation loss: 0.202\n",
            "validation accuracy: 93.02 %\n",
            "\n",
            "Epoch 67\n",
            "training loss: 0.174\n",
            "training accuracy: 93.70 %\n",
            "validation loss: 0.195\n",
            "validation accuracy: 93.08 %\n",
            "model saved\n",
            "\n",
            "Epoch 68\n",
            "training loss: 0.175\n",
            "training accuracy: 93.54 %\n",
            "validation loss: 0.195\n",
            "validation accuracy: 93.28 %\n",
            "\n",
            "Epoch 69\n",
            "training loss: 0.173\n",
            "training accuracy: 93.71 %\n",
            "validation loss: 0.197\n",
            "validation accuracy: 93.18 %\n",
            "\n",
            "Epoch 70\n",
            "training loss: 0.171\n",
            "training accuracy: 93.74 %\n",
            "validation loss: 0.199\n",
            "validation accuracy: 93.03 %\n",
            "\n",
            "Epoch 71\n",
            "training loss: 0.169\n",
            "training accuracy: 93.77 %\n",
            "validation loss: 0.201\n",
            "validation accuracy: 93.23 %\n",
            "\n",
            "Epoch 72\n",
            "training loss: 0.174\n",
            "training accuracy: 93.56 %\n",
            "validation loss: 0.194\n",
            "validation accuracy: 93.43 %\n",
            "model saved\n",
            "\n",
            "Epoch 73\n",
            "training loss: 0.169\n",
            "training accuracy: 93.75 %\n",
            "validation loss: 0.196\n",
            "validation accuracy: 93.36 %\n",
            "\n",
            "Epoch 74\n",
            "training loss: 0.171\n",
            "training accuracy: 93.68 %\n",
            "validation loss: 0.194\n",
            "validation accuracy: 93.29 %\n",
            "\n",
            "Epoch 75\n",
            "training loss: 0.167\n",
            "training accuracy: 93.81 %\n",
            "validation loss: 0.200\n",
            "validation accuracy: 93.07 %\n",
            "\n",
            "Epoch 76\n",
            "training loss: 0.170\n",
            "training accuracy: 93.79 %\n",
            "validation loss: 0.197\n",
            "validation accuracy: 93.03 %\n",
            "\n",
            "Epoch 77\n",
            "training loss: 0.167\n",
            "training accuracy: 93.80 %\n",
            "validation loss: 0.194\n",
            "validation accuracy: 93.21 %\n",
            "\n",
            "Epoch 78\n",
            "training loss: 0.170\n",
            "training accuracy: 93.84 %\n",
            "validation loss: 0.201\n",
            "validation accuracy: 93.27 %\n",
            "\n",
            "Epoch 79\n",
            "training loss: 0.167\n",
            "training accuracy: 93.88 %\n",
            "validation loss: 0.195\n",
            "validation accuracy: 93.34 %\n",
            "\n",
            "Epoch 80\n",
            "training loss: 0.167\n",
            "training accuracy: 93.81 %\n",
            "validation loss: 0.198\n",
            "validation accuracy: 93.36 %\n",
            "\n",
            "Epoch 81\n",
            "training loss: 0.166\n",
            "training accuracy: 93.91 %\n",
            "validation loss: 0.196\n",
            "validation accuracy: 93.21 %\n",
            "\n",
            "Epoch 82\n",
            "training loss: 0.164\n",
            "training accuracy: 93.93 %\n",
            "validation loss: 0.198\n",
            "validation accuracy: 93.06 %\n",
            "\n",
            "Epoch 83\n",
            "training loss: 0.165\n",
            "training accuracy: 93.91 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.46 %\n",
            "model saved\n",
            "\n",
            "Epoch 84\n",
            "training loss: 0.165\n",
            "training accuracy: 93.89 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.49 %\n",
            "\n",
            "Epoch 85\n",
            "training loss: 0.162\n",
            "training accuracy: 93.97 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.43 %\n",
            "\n",
            "Epoch 86\n",
            "training loss: 0.163\n",
            "training accuracy: 93.95 %\n",
            "validation loss: 0.193\n",
            "validation accuracy: 93.28 %\n",
            "\n",
            "Epoch 87\n",
            "training loss: 0.164\n",
            "training accuracy: 93.93 %\n",
            "validation loss: 0.193\n",
            "validation accuracy: 93.29 %\n",
            "\n",
            "Epoch 88\n",
            "training loss: 0.163\n",
            "training accuracy: 94.12 %\n",
            "validation loss: 0.196\n",
            "validation accuracy: 93.15 %\n",
            "\n",
            "Epoch 89\n",
            "training loss: 0.163\n",
            "training accuracy: 93.95 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.30 %\n",
            "\n",
            "Epoch 90\n",
            "training loss: 0.161\n",
            "training accuracy: 94.08 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.55 %\n",
            "\n",
            "Epoch 91\n",
            "training loss: 0.159\n",
            "training accuracy: 94.19 %\n",
            "validation loss: 0.193\n",
            "validation accuracy: 93.50 %\n",
            "\n",
            "Epoch 92\n",
            "training loss: 0.160\n",
            "training accuracy: 94.18 %\n",
            "validation loss: 0.195\n",
            "validation accuracy: 93.36 %\n",
            "\n",
            "Epoch 93\n",
            "training loss: 0.160\n",
            "training accuracy: 94.20 %\n",
            "validation loss: 0.187\n",
            "validation accuracy: 93.49 %\n",
            "model saved\n",
            "\n",
            "Epoch 94\n",
            "training loss: 0.159\n",
            "training accuracy: 94.08 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.39 %\n",
            "\n",
            "Epoch 95\n",
            "training loss: 0.158\n",
            "training accuracy: 94.16 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.55 %\n",
            "\n",
            "Epoch 96\n",
            "training loss: 0.159\n",
            "training accuracy: 94.06 %\n",
            "validation loss: 0.188\n",
            "validation accuracy: 93.45 %\n",
            "\n",
            "Epoch 97\n",
            "training loss: 0.160\n",
            "training accuracy: 94.10 %\n",
            "validation loss: 0.191\n",
            "validation accuracy: 93.72 %\n",
            "\n",
            "Epoch 98\n",
            "training loss: 0.159\n",
            "training accuracy: 94.13 %\n",
            "validation loss: 0.193\n",
            "validation accuracy: 93.68 %\n",
            "\n",
            "Epoch 99\n",
            "training loss: 0.156\n",
            "training accuracy: 94.22 %\n",
            "validation loss: 0.192\n",
            "validation accuracy: 93.49 %\n",
            "\n",
            "Epoch 100\n",
            "training loss: 0.157\n",
            "training accuracy: 94.25 %\n",
            "validation loss: 0.193\n",
            "validation accuracy: 93.51 %\n",
            "\n",
            "Epoch 101\n",
            "training loss: 0.156\n",
            "training accuracy: 94.29 %\n",
            "validation loss: 0.203\n",
            "validation accuracy: 93.21 %\n",
            "\n",
            "Epoch 102\n",
            "training loss: 0.158\n",
            "training accuracy: 94.21 %\n",
            "validation loss: 0.192\n",
            "validation accuracy: 93.52 %\n",
            "\n",
            "Epoch 103\n",
            "training loss: 0.155\n",
            "training accuracy: 94.34 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.75 %\n",
            "\n",
            "Epoch 104\n",
            "training loss: 0.155\n",
            "training accuracy: 94.30 %\n",
            "validation loss: 0.194\n",
            "validation accuracy: 93.12 %\n",
            "\n",
            "Epoch 105\n",
            "training loss: 0.155\n",
            "training accuracy: 94.25 %\n",
            "validation loss: 0.193\n",
            "validation accuracy: 93.34 %\n",
            "\n",
            "Epoch 106\n",
            "training loss: 0.153\n",
            "training accuracy: 94.27 %\n",
            "validation loss: 0.192\n",
            "validation accuracy: 93.36 %\n",
            "\n",
            "Epoch 107\n",
            "training loss: 0.154\n",
            "training accuracy: 94.38 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.49 %\n",
            "\n",
            "Epoch 108\n",
            "training loss: 0.154\n",
            "training accuracy: 94.40 %\n",
            "validation loss: 0.193\n",
            "validation accuracy: 93.56 %\n",
            "\n",
            "Epoch 109\n",
            "training loss: 0.153\n",
            "training accuracy: 94.29 %\n",
            "validation loss: 0.191\n",
            "validation accuracy: 93.41 %\n",
            "\n",
            "Epoch 110\n",
            "training loss: 0.151\n",
            "training accuracy: 94.43 %\n",
            "validation loss: 0.189\n",
            "validation accuracy: 93.52 %\n",
            "\n",
            "Epoch 111\n",
            "training loss: 0.151\n",
            "training accuracy: 94.41 %\n",
            "validation loss: 0.189\n",
            "validation accuracy: 93.64 %\n",
            "\n",
            "Epoch 112\n",
            "training loss: 0.150\n",
            "training accuracy: 94.50 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.55 %\n",
            "\n",
            "Epoch 113\n",
            "training loss: 0.153\n",
            "training accuracy: 94.40 %\n",
            "validation loss: 0.193\n",
            "validation accuracy: 93.52 %\n",
            "\n",
            "Epoch 114\n",
            "training loss: 0.150\n",
            "training accuracy: 94.48 %\n",
            "validation loss: 0.195\n",
            "validation accuracy: 93.38 %\n",
            "\n",
            "Epoch 115\n",
            "training loss: 0.152\n",
            "training accuracy: 94.30 %\n",
            "validation loss: 0.189\n",
            "validation accuracy: 93.45 %\n",
            "\n",
            "Epoch 116\n",
            "training loss: 0.151\n",
            "training accuracy: 94.50 %\n",
            "validation loss: 0.188\n",
            "validation accuracy: 93.64 %\n",
            "\n",
            "Epoch 117\n",
            "training loss: 0.152\n",
            "training accuracy: 94.47 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.66 %\n",
            "\n",
            "Epoch 118\n",
            "training loss: 0.150\n",
            "training accuracy: 94.51 %\n",
            "validation loss: 0.195\n",
            "validation accuracy: 93.37 %\n",
            "\n",
            "Epoch 119\n",
            "training loss: 0.150\n",
            "training accuracy: 94.42 %\n",
            "validation loss: 0.198\n",
            "validation accuracy: 93.18 %\n",
            "\n",
            "Epoch 120\n",
            "training loss: 0.150\n",
            "training accuracy: 94.50 %\n",
            "validation loss: 0.195\n",
            "validation accuracy: 93.31 %\n",
            "\n",
            "Epoch 121\n",
            "training loss: 0.150\n",
            "training accuracy: 94.48 %\n",
            "validation loss: 0.193\n",
            "validation accuracy: 93.33 %\n",
            "\n",
            "Epoch 122\n",
            "training loss: 0.149\n",
            "training accuracy: 94.40 %\n",
            "validation loss: 0.194\n",
            "validation accuracy: 93.22 %\n",
            "\n",
            "Epoch 123\n",
            "training loss: 0.148\n",
            "training accuracy: 94.59 %\n",
            "validation loss: 0.192\n",
            "validation accuracy: 93.48 %\n",
            "\n",
            "Epoch 124\n",
            "training loss: 0.146\n",
            "training accuracy: 94.62 %\n",
            "validation loss: 0.187\n",
            "validation accuracy: 93.57 %\n",
            "\n",
            "Epoch 125\n",
            "training loss: 0.148\n",
            "training accuracy: 94.55 %\n",
            "validation loss: 0.189\n",
            "validation accuracy: 93.56 %\n",
            "\n",
            "Epoch 126\n",
            "training loss: 0.148\n",
            "training accuracy: 94.61 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.36 %\n",
            "\n",
            "Epoch 127\n",
            "training loss: 0.149\n",
            "training accuracy: 94.50 %\n",
            "validation loss: 0.187\n",
            "validation accuracy: 93.60 %\n",
            "\n",
            "Epoch 128\n",
            "training loss: 0.147\n",
            "training accuracy: 94.55 %\n",
            "validation loss: 0.191\n",
            "validation accuracy: 93.32 %\n",
            "\n",
            "Epoch 129\n",
            "training loss: 0.148\n",
            "training accuracy: 94.50 %\n",
            "validation loss: 0.192\n",
            "validation accuracy: 93.24 %\n",
            "\n",
            "Epoch 130\n",
            "training loss: 0.145\n",
            "training accuracy: 94.70 %\n",
            "validation loss: 0.187\n",
            "validation accuracy: 93.58 %\n",
            "\n",
            "Epoch 131\n",
            "training loss: 0.147\n",
            "training accuracy: 94.63 %\n",
            "validation loss: 0.190\n",
            "validation accuracy: 93.22 %\n",
            "\n",
            "Epoch 132\n",
            "training loss: 0.145\n",
            "training accuracy: 94.65 %\n",
            "validation loss: 0.194\n",
            "validation accuracy: 93.27 %\n",
            "\n",
            "Epoch 133\n",
            "training loss: 0.146\n",
            "training accuracy: 94.52 %\n",
            "validation loss: 0.189\n",
            "validation accuracy: 93.28 %\n",
            "Training is finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOSgKYCud23Z",
        "colab_type": "code",
        "outputId": "ab36b138-83e1-4307-d523-b8d0055dd9d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "  net = net.eval()\n",
        "  val_loss = 0.0\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  confusion_matrix = torch.zeros(len(classes), len(classes))\n",
        "  for i, data in enumerate(testloader, 1):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs = net(inputs)\n",
        "    val_loss += criterion(outputs, labels).item()\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    for l, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "      confusion_matrix[l.long(), p.long()] += 1\n",
        "print('validation loss: %.3f' % \n",
        "      (val_loss/i,))\n",
        "\n",
        "print('validation accuracy: %.2f %%\\n' % \n",
        "      (100*correct/total,))\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation loss: 0.187\n",
            "validation accuracy: 93.49 %\n",
            "\n",
            "tensor([[892.,   0.,  15.,  16.,   1.,   0.,  67.,   0.,   9.,   0.],\n",
            "        [  0., 984.,   0.,  10.,   0.,   0.,   4.,   0.,   2.,   0.],\n",
            "        [ 10.,   0., 915.,  10.,  20.,   0.,  45.,   0.,   0.,   0.],\n",
            "        [ 12.,   1.,   5., 938.,  22.,   0.,  21.,   0.,   1.,   0.],\n",
            "        [  1.,   0.,  41.,  18., 907.,   0.,  32.,   0.,   1.,   0.],\n",
            "        [  0.,   0.,   0.,   0.,   0., 980.,   0.,  15.,   0.,   5.],\n",
            "        [ 79.,   0.,  45.,  23.,  53.,   0., 796.,   0.,   4.,   0.],\n",
            "        [  0.,   0.,   0.,   0.,   0.,   6.,   0., 976.,   0.,  18.],\n",
            "        [  4.,   0.,   0.,   2.,   2.,   1.,   0.,   0., 991.,   0.],\n",
            "        [  0.,   0.,   0.,   0.,   0.,   6.,   0.,  24.,   0., 970.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTbVEk4ge44f",
        "colab_type": "text"
      },
      "source": [
        "Accuracy on validation set for trained model equals 93,49%. Model was trained for 134 epochs but the best weights model had after 94 epochs.\n",
        "The worst accuracy is for classes Shirt (79,6%) and T-shirt (89,2%), the best for class Bag (99,3%). Again the most often model confuses objects of classes T-shirt and Shirt. Model is less biased: the most popular class was selected 1021 times, the least popular 965 times."
      ]
    }
  ]
}